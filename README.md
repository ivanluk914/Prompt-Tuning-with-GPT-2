# Prompt-Tuning-with-GPT-2
This project uses prompt tuning with the PEFT library to improve GPT-2's task-specific performance by training virtual tokens. It achieves better, context-relevant responses with minimal resources using the fka/awesome-chatgpt-prompts dataset.
